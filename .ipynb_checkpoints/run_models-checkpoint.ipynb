{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pickle\n",
    "from paths import *\n",
    "from keras.preprocessing.text import one_hot\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Flatten\n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pickle\n",
    "from paths import *\n",
    "from keras.layers.convolutional import Convolution1D\n",
    "from keras.layers.convolutional import MaxPooling1D\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import  GRU\n",
    "from create_embedding import *\n",
    "from helper import *\n",
    "from create_emebedding import *\n",
    "from paths import *\n",
    "from tweet_vectors import *\n",
    "from keras.layers import Bidirectional"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_dl_model():\n",
    "    print('preprocessing')\n",
    "    X_pos, X_neg,  X_test = load_cleaned_data_and_test(DATASETS_PATH + 'train_pos_full.txt', \\\n",
    "                   DATASETS_PATH + 'train_neg_full.txt', DATASETS_PATH + 'test_data.txt' ,HASHTAG = True, EMPHASIZE = True, PUNC=True, NUMBER =True, SMALL_WORDS = True , \\\n",
    "                        SLANG =True, APOSTROPHE = True, EMOJI = False, REPITITION = True , SPELLING = True, \\\n",
    "                        STOPWORDS = False, LEMMATIZE = False, STEMMING = False)\n",
    "    X = X_pos + X_neg\n",
    "    #save full cleaned datasets\n",
    "    pickle.dump(X, open(CLEANED_DATA_PATH + 'full_X_Cleaned.pkl', 'wb'))\n",
    "    pickle.dump(X_test, open(CLEANED_DATA_PATH + 'full_X_test_Cleaned.pkl', 'wb'))\n",
    "    print('using values 200 and 30 respectively for dimension and max_length')\n",
    "    dimension = 200\n",
    "    MAX_LENGTH = 30\n",
    "    sequence_X , sequence_test , embedding_matrix , y , vocab_size = prepare_DL_input(X , X_test , dimension , MAX_LENGTH )\n",
    "    #put best model here \n",
    "    print('building model')\n",
    "    model = Sequential()\n",
    "    model.add(Embedding(vocab_size, dimension, input_length=MAX_LENGTH, weights=[embedding_matrix]))\n",
    "    model.add(Bidirectional(LSTM(100, dropout=0.2)))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    print('training model')\n",
    "    model.fit(sequence_X, y, epochs=2, batch_size=128, verbose=1, shuffle=True)\n",
    "    print('prediction')\n",
    "    pred = model.predict_proba(sequence_test)  \n",
    "    new_pred = [1 if x <= 0.5 else -1 for x in pred]\n",
    "    ids = np.arange(1,10001)\n",
    "    name = 'BestModel.csv'\n",
    "    create_csv_submission(ids,new_pred,name)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
