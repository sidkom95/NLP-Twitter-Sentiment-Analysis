{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from helper import *\n",
    "import pickle\n",
    "from paths import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Data processing\n",
      "Processing urls , user names and mentions\n",
      "Processing repetition\n",
      "Processing haha..s\n",
      "Processing slang words\n",
      "Processing spelling mistakes\n",
      "processing hashtags\n",
      "Processing apostrophes\n",
      "Processing emphasize sentiment words\n",
      "Processing punctuation\n",
      "Processing numbers\n",
      "Processing small words\n",
      "Processing spelling mistakes a second time\n",
      "Returning Positive X data , Negative X data and test data\n"
     ]
    }
   ],
   "source": [
    "# load full cleaned datasets \n",
    "X_pos, X_neg,  X_test = load_cleaned_data_and_test(DATASETS_PATH + 'train_pos_full.txt', \\\n",
    "                   DATASETS_PATH + 'train_neg_full.txt', DATASETS_PATH + 'test_data.txt' ,HASHTAG = True, EMPHASIZE = True, PUNC=True, NUMBER =True, SMALL_WORDS = True , \\\n",
    "                        SLANG =True, APOSTROPHE = True, EMOJI = False, REPITITION = True , SPELLING = True, \\\n",
    "                        STOPWORDS = False, LEMMATIZE = False, STEMMING = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X_pos + X_neg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save full cleaned datasets\n",
    "pickle.dump(X, open(CLEANED_DATA_PATH + 'full_X_Cleaned.pkl', 'wb'))\n",
    "pickle.dump(X_test, open(CLEANED_DATA_PATH + 'full_X_test_Cleaned.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load clean sample of datasets 10% for testing \n",
    "X_pos, X_neg,  X_test = load_cleaned_data_and_test(DATASETS_PATH + 'train_pos.txt', \\\n",
    "                   DATASETS_PATH + 'train_neg.txt', DATASETS_PATH + 'test_data.txt' ,HASHTAG = True, EMPHASIZE = True, PUNC=True, NUMBER =True, SMALL_WORDS = True , \\\n",
    "                        SLANG =True, APOSTROPHE = True, EMOJI = False, REPITITION = False, SPELLING = True, \\\n",
    "                        STOPWORDS = False, LEMMATIZE = False, STEMMING = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X_pos + X_neg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save clean sample of datasets 10%\n",
    "pickle.dump(X, open(CLEANED_DATA_PATH + 'sample_X_Cleaned.pkl', 'wb'))\n",
    "pickle.dump(X_test, open(CLEANED_DATA_PATH + 'sample_X_test_Cleaned.pkl', 'wb'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
